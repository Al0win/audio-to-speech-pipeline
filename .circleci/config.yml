version: 2.1

parameters:
  # This parameter is used to trigger the main workflow
  trigger:
    type: boolean
    default: false

  # A parameter per package
  pipeline_workflows:
    type: boolean
    default: true
  data_tagger:
    type: boolean
    default: true
  data_prep_cataloguer:
    type: boolean
    default: true
  ekstep_data_pipelines:
    type: boolean
    default: true

executors:
  node:
    docker:
      - image: circleci/python:3.8.6

jobs:
  trigger-workflows:
    executor: node
    steps:
      - checkout
      - run:
          name: Trigger workflows
          command: chmod +x .circleci/circle_trigger.sh && .circleci/circle_trigger.sh

  build-dags:
    parameters:
      package_name:
        type: string
      env_name:
        type: string
    machine:
      image: ubuntu-1604:201903-01
    working_directory: ~/project/packages/<< parameters.package_name >>
    steps:
      - checkout:
          path: ~/project
      - run:
          name: Build Image
          command: |
            ls -ltr . ; pwd
      #            export DOCKER_BUILDKIT=1
      #            docker build --rm=false -t img-pipeline_workflows:latest .
      #            - run:
      #                name: Save Docker image
      #                command: |
      #                  docker save -o img-pipeline_workflows
      #      - run:
      #          name: Test Pipeline Workflow DAG
      #          command: |
      #            docker run -ti -v ~/project/packages/<< parameters.package_name >>:/opt/pipeline_workflows --entrypoint /mnt/entrypoint.sh img-pipeline_workflows run_unit_tests
      - run:
          name: Deploy Pipeline Workflow DAG
          command: |
            echo ${GOOGLE_AUTH} > ${HOME}/gcp-key.json
            gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
            gcloud --quiet config set project ${GCP_PROJECT}
            sh ~/project/packages/<< parameters.package_name >>/deployDAG.sh << parameters.env_name >>
            rm ${HOME}/gcp-key.json

  build:
    parameters:
      package_name:
        type: string

    executor: node
    working_directory: ~/project/packages/<< parameters.package_name >>

    steps:
      - checkout:
          path: ~/project
      # This step is added only to show that we are in the package directory
      - run:
          name: Sanity check to confirm correct package directory
          command: echo "Current package directory is << parameters.package_name >> ..."
      - run:
          name: Setup Testing Environment
          command: |
            pyenv global 3.8.6
            sudo apt-get update
            sudo apt-get install -y ffmpeg
            sudo apt-get install -y sox
            sudo apt-get install -y gcc-multilib g++-multilib
            sudo apt-get install libpq-dev
            pip install --upgrade pip
            pip install -r requirements.txt
            python --version ; pip --version ; pwd ; ls
      - run:
          name: Run Tests
          command: |
            coverage run -m unittest discover src/tests
            coverage report --fail-under 20  src/scripts/*.py
            coverage html  # open htmlcov/index.html in a browser
      - store_artifacts:
          path: htmlcov
      - persist_to_workspace:
          root: ~/project
          paths:
            - packages/<< parameters.package_name >>

  ekstep_build:
    parameters:
      package_name:
        type: string

    executor: node
    working_directory: ~/project/packages/<< parameters.package_name >>

    steps:
      - checkout:
          path: ~/project
      # This step is added only to show that we are in the package directory
      - run:
          name: Sanity check to confirm correct package directory
          command: echo "Current package directory is << parameters.package_name >> ..."
      - run:
          name: Setup Testing Environment
          command: |
            python --version ; pip --version ; pwd ; ls
            sudo apt-get update
            sudo apt-get install -y ffmpeg
            sudo apt-get install -y sox
            sudo apt-get install -y gcc-multilib g++-multilib
            sudo apt-get install libpq-dev
            pip install --upgrade pip
            pip install -r requirements.txt
            python --version ; pip --version ; pwd ; ls
      - run:
          name: Run Tests
          command: |
            # python -m unittest discover -s ekstep_pipelines_tests/ -p "*_tests.py" -v
            coverage run -m unittest discover -s ekstep_pipelines_tests/ -p "*_tests.py" -v
            python -m unittest discover -s ekstep_pipelines_tests/common/audio_commons/ -p "*_tests.py" -v
            python -m unittest discover -s ekstep_pipelines_tests/common/audio_commons/transcription_clients_tests -p "*_tests.py" -v
            python -m unittest discover -s ekstep_pipelines_tests/audio_language_identification -p "*tests.py" -v
            # coverage report --fail-under 20  data_marker/*.py
            # coverage html  # open htmlcov/index.html in a browser
      - store_artifacts:
          path: htmlcov
      - persist_to_workspace:
          root: ~/project
          paths:
            - packages/<< parameters.package_name >>
  deploy:
    parameters:
      package_name:
        type: string
      package_version:
        type: string
      env_name:
        type: string
    #    executor: node
    machine:
      image: ubuntu-1604:201903-01
    working_directory: ~/project/packages/<< parameters.package_name >>

    steps:
      - attach_workspace:
          at: ~/project
      # This step is added to show that files are available from the build job.
      - run:
          name: Content to deploy
          command: ls
      - deploy:
          name: Build and Deploy Image
          command: |
            echo ${GOOGLE_AUTH} > ${HOME}/gcp-key.json
            gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
            gcloud --quiet config set project ${GCP_PROJECT}
            if [[ << parameters.env_name >> == "test" ]]; then
              echo "Build << parameters.package_name >> ..."
              docker build --rm=false -t us.gcr.io/${GCP_PROJECT}/<< parameters.package_name >>:<< parameters.package_version >> -t us.gcr.io/${GCP_PROJECT}/<< parameters.package_name >>:<< parameters.env_name >>_<< parameters.package_version >> .
            else
             echo "Pull << parameters.package_name >> ..."
             gcloud docker -- pull us.gcr.io/${GCP_PROJECT}/<< parameters.package_name >>:<< parameters.package_version >>
             echo "Tag << parameters.package_name >> ... with << parameters.env_name >>"
             docker tag us.gcr.io/${GCP_PROJECT}/<< parameters.package_name >>:<< parameters.package_version >> us.gcr.io/${GCP_PROJECT}/<< parameters.package_name >>:<< parameters.env_name >>_<< parameters.package_version >>
            fi
            gcloud docker -- push us.gcr.io/${GCP_PROJECT}/<< parameters.package_name >>
      - run:
          name: Remove account details
          command: rm ${HOME}/gcp-key.json ; ls
  approval_for_prod_deploy:
    docker:
      - image: circleci/node:4.8.2
    steps:
      - run: echo "Hold for approval"

workflows:
  version: 2

  # The main workflow responsible for triggering all other workflows
  # in which changes are detected.
  ci:
    when: << pipeline.parameters.trigger >>
    jobs:
      - trigger-workflows


  # Workflows defined for each package.

  data_tagger:
    when: << pipeline.parameters.data_tagger >>
    jobs:
      - build:
          name: data_tagger_build
          package_name: data_tagger
      - deploy:
          name: data_tagger_deploy_test
          package_name: data_tagger
          package_version: 1.0.0
          env_name: test
          requires:
            - data_tagger_build
      - deploy:
          name: data_tagger_deploy_prod
          package_name: data_tagger
          package_version: 1.0.0
          env_name: prod
          requires:
            - data_tagger_build
            - data_tagger_deploy_test

          # filters:
          #   branches:
          #     only:
          #       - master

  data_prep_cataloguer:
    when: << pipeline.parameters.data_prep_cataloguer >>
    jobs:
      - build:
          name: data_prep_cataloguer_build
          package_name: data_prep_cataloguer
      - deploy:
          name: data_prep_cataloguer_deploy_test
          package_name: data_prep_cataloguer
          package_version: 1.0.0
          env_name: test
          requires:
            - data_prep_cataloguer_build
      - approval_for_prod_deploy:
          type: approval
          requires:
            - data_prep_cataloguer_deploy_test
      - deploy:
          name: data_prep_cataloguer_deploy_prod
          package_name: data_prep_cataloguer
          package_version: 1.0.0
          env_name: prod
          requires:
            - data_prep_cataloguer_build
            - approval_for_prod_deploy
          # filters:
          #   branches:
          #     only:
          #       - master

  ekstep_data_pipelines:
    when: << pipeline.parameters.ekstep_data_pipelines >>
    jobs:
      - ekstep_build:
          name: ekstep_data_pipelines_build
          package_name: ekstep_data_pipelines
      - deploy:
          name: ekstep_data_pipelines_deploy_test
          package_name: ekstep_data_pipelines
          env_name: test
          package_version: 1.0.0
          requires:
            - ekstep_data_pipelines_build
      - approval_for_prod_deploy:
          type: approval
          requires:
            - ekstep_data_pipelines_deploy_test
      - deploy:
          name: ekstep_data_pipelines_deploy_prod
          package_name: ekstep_data_pipelines
          env_name: approval_for_prod_deploy
          package_version: 1.0.0
          requires:
            - ekstep_data_pipelines_build
            - approval_for_prod_deploy

  pipeline_workflows:
    when: << pipeline.parameters.pipeline_workflows >>
    jobs:
      - build-dags:
          name: pipeline-dag-build_test
          package_name: pipeline_workflows
          env_name: 'test'
      - build-dags:
          name: pipeline-dag-build_prod
          package_name: pipeline_workflows
          env_name: 'prod'
          requires:
            - pipeline-dag-build_test

